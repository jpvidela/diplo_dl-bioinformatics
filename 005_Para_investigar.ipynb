{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc92861-86dc-44ad-b27c-b5ffd044472a",
   "metadata": {},
   "source": [
    "# ¿Que más se podría hacer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704dd533-a652-4bbf-97b9-e2923e11d78d",
   "metadata": {},
   "source": [
    "- Test con data augmentation y la LSTM\n",
    "- Usar los tokenizadores usados en los transformers para ver como funcionan\n",
    "- TSNE de embeddings y analizar si hay interpretación\n",
    "- Probar con otras encimas o proteinas\n",
    "- Usar los embeddings entrenados para analizar resultados de proteinas o encimas con menos data\n",
    "- Entrenar una red neuronal con los features (fingerprints por ejemplo) y comparar los resultados con los embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2085f015-56fa-4364-958d-b7a0786372af",
   "metadata": {},
   "source": [
    "# Tome cualquiera de estas propuestas o alguna suya y desarrolle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265e45e",
   "metadata": {},
   "source": [
    "### Imports Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d300e8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM, Embedding, Bidirectional, Activation, Input, Conv1D, MaxPool1D, Concatenate, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "from datagen import smiles_dict, smiles_to_seq, DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda68d7-f66c-4457-a876-9a8808961880",
   "metadata": {},
   "source": [
    "## Test con data augmentation & LSTM\n",
    "\n",
    "Reentreno la LSTM de la notebook 003 con la misma técnica de Data Augmentation implementada en la notebook 004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a594829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/acetylcholinesterase_02_bioactivity_data_preprocessed.csv')\n",
    "\n",
    "max_len_idx = df['canonical_smiles'].apply(len).argmax()\n",
    "min_len_idx = df['canonical_smiles'].apply(len).argmin()\n",
    "max_sequence_len = len(df['canonical_smiles'].iloc[max_len_idx]) + 20\n",
    "X = df['canonical_smiles'].values\n",
    "y = df['pIC50'].values\n",
    "vocab_size = len(smiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8442c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgen_train = DataGenerator(X_train, y_train, seq_length=max_sequence_len, batch_size=128, data_augmentation=True)\n",
    "dgen_test = DataGenerator(X_test, y_test, seq_length=max_sequence_len, batch_size=128, data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIAR Y PEGAR MODELO LSTM DE NOTEBOOK 003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14329abc",
   "metadata": {},
   "source": [
    "## TSNE de embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14106df",
   "metadata": {},
   "source": [
    "## Red Neuronal con Fingerprints y comparación con embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee4255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo csv generado a partir de las notebooks de los videos\n",
    "df = pd.read_csv('data/acetylcholinesterase_06_bioactivity_data_3class_pIC50_pubchem_fp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('pIC50', axis=1)\n",
    "Y = df.pIC50\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retengo columnas con mayor variabilidad\n",
    "selection = VarianceThreshold(threshold=(.8 * (1 - .8)))    \n",
    "X = selection.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/ Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb0818c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('final_nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f946e8aec543dfca951bb256c946f0b98ef4fd8b529db6e20fe9e7661b6a067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
